import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import re
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
import os
import matplotlib.font_manager as fm
import ssl
import psycopg2
from psycopg2.extras import RealDictCursor
import json

import matplotlib as mpl
mpl.font_manager.fontManager.addfont('fonts/THSarabunNew.ttf') # Ensuring matplotlib recognizes the font
mpl.rc('font', family='TH Sarabun New') # Setting the default font to TH Sarabun New

# Fix for the SSL certificate issue with NLTK
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Only import wordcloud and nltk if needed - with error handling
try:
    from wordcloud import WordCloud
    import nltk
    from nltk.corpus import stopwords
    nltk.download('stopwords', quiet=True)
    nltk_available = True
except ImportError:
    nltk_available = False
    st.warning("WordCloud and/or NLTK not available. Text analysis features will be limited.")

# Only import pythainlp if needed - with error handling
try:
    from pythainlp.tokenize import word_tokenize
    from pythainlp.corpus import thai_stopwords
    pythainlp_available = True
except ImportError:
    pythainlp_available = False
    st.warning("PythaiNLP not available. Thai language processing will be limited.")

# Thai font setup
try:
    thai_font_path = os.path.join("fonts", "THSarabunNew.ttf")
    if os.path.exists(thai_font_path):
        font_prop = fm.FontProperties(fname=thai_font_path)
    else:
        font_prop = None
except Exception:
    font_prop = None

# Set page configuration
st.set_page_config(
    page_title="Traffy Fondue Data Analysis",
    page_icon="ðŸ“Š",
    layout="wide"
)

# Add title and description
st.title("ðŸ“Š Traffy Fondue Data Analysis Dashboard")
st.markdown("""
This dashboard analyzes data from Traffy Fondue, a platform for citizens to report urban issues in Bangkok.
Explore the patterns, response times, and common problems reported by citizens.
""")

# Database configuration - with environment variable support
DB_HOST = os.getenv("DB_HOST", "localhost")  # Default to localhost instead of postgres
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "airflow")
DB_USER = os.getenv("DB_USER", "airflow")
DB_PASSWORD = os.getenv("DB_PASSWORD", "airflow")

# Function to connect to PostgreSQL
def connect_to_db():
    try:
        st.info(f"Connecting to database at {DB_HOST}:{DB_PORT}...")
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        st.success("Database connection established!")
        return conn
    except Exception as e:
        st.error(f"Error connecting to database: {e}")
        st.info("""
        **Database Connection Troubleshooting:**
        1. Make sure PostgreSQL is running
        2. Check your connection settings
        3. If running locally, try setting DB_HOST to 'localhost'
        4. If running in Docker, make sure the network is properly configured
        
        You can set database connection parameters using environment variables:
        - DB_HOST: Database hostname (default: localhost)
        - DB_PORT: Database port (default: 5432)
        - DB_NAME: Database name (default: airflow)
        - DB_USER: Database username (default: airflow)
        - DB_PASSWORD: Database password (default: airflow)
        """)
        return None

# Function to load and preprocess data from PostgreSQL
@st.cache_data(ttl=300)  # Cache data for 5 minutes
def load_data():
    conn = connect_to_db()
    if conn is None:
        # Add option for demo data when DB connection fails
        use_demo = st.checkbox("Use demo data instead?", value=True)
        if use_demo:
            st.info("Using demo data. Note that this is not real-time data.")
            # Try to load demo data from a local file if available
            try:
                demo_file = "data_and_rain.csv"
                if os.path.exists(demo_file):
                    # Load demo data
                    df = pd.read_csv(demo_file, nrows=1000)
                    
                    # Convert timestamp and last_activity to datetime
                    if 'timestamp' in df.columns:
                        df['timestamp'] = pd.to_datetime(df['timestamp'])
                    if 'last_activity' in df.columns:
                        df['last_activity'] = pd.to_datetime(df['last_activity'])
                    
                    # Calculate resolution time in hours (if needed)
                    if 'timestamp' in df.columns and 'last_activity' in df.columns:
                        df['resolution_time_hours'] = (df['last_activity'] - df['timestamp']).dt.total_seconds() / 3600
                        df['resolution_time_days'] = df['resolution_time_hours'] / 24
                    
                    # Process array fields if they exist in the demo data
                    # In CSV, these might be stored as strings that look like lists
                    if 'type' in df.columns:
                        try:
                            df['type_list'] = df['type'].apply(lambda x: str(x).split(',') if pd.notna(x) else [])
                            df['type_list_str'] = df['type_list'].apply(lambda x: str(x))
                        except:
                            df['type_list'] = [[] for _ in range(len(df))]
                            df['type_list_str'] = df['type_list'].apply(lambda x: str(x))
                    
                    if 'organization' in df.columns:
                        try:
                            df['organization_list'] = df['organization'].apply(lambda x: str(x).split(',') if pd.notna(x) else [])
                            df['organization_list_str'] = df['organization_list'].apply(lambda x: str(x))
                        except:
                            df['organization_list'] = [[] for _ in range(len(df))]
                            df['organization_list_str'] = df['organization_list'].apply(lambda x: str(x))
                    
                    # Extract coordinates if stored in a single field
                    if 'coords' in df.columns:
                        try:
                            # Try to extract coordinates if they're in "lat,long" format
                            df[['latitude', 'longitude']] = df['coords'].str.split(',', expand=True).astype(float)
                        except:
                            st.warning("Could not parse coordinates from the coords column.")
                    
                    # Fill missing district information
                    if 'district' in df.columns:
                        df['district'] = df['district'].fillna('à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸')
                    
                    st.success(f"Successfully loaded demo data with {len(df)} records")
                    return df
                else:
                    st.error("Demo data file not found")
            except Exception as e:
                st.error(f"Error loading demo data: {e}")
        return pd.DataFrame()
    
    try:
        # Use RealDictCursor to get column names
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # Query to get all issues
        query = """
        SELECT 
            id, 
            message_id, 
            type,
            ST_X(coordinates::geometry) as longitude,
            ST_Y(coordinates::geometry) as latitude,
            problem_type_fondue,
            org,
            org_action,
            description,
            photo_url,
            address,
            subdistrict,
            district,
            province,
            timestamp,
            state,
            last_activity
        FROM issues;
        """
        
        cursor.execute(query)
        results = cursor.fetchall()
        
        # Convert to DataFrame
        df = pd.DataFrame(results)
        
        # Close connection
        cursor.close()
        conn.close()
        
        # If DataFrame is empty, return it
        if df.empty:
            st.warning("No data found in the database. The table might be empty.")
            return df
        
        # Convert timestamp and last_activity to datetime
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['last_activity'] = pd.to_datetime(df['last_activity'])
        
        # Calculate resolution time in hours
        df['resolution_time_hours'] = (df['last_activity'] - df['timestamp']).dt.total_seconds() / 3600
        df['resolution_time_days'] = df['resolution_time_hours'] / 24
        
        # Process array fields (problem_type_fondue, org, org_action)
        # Convert PostgreSQL arrays to Python lists
        if 'problem_type_fondue' in df.columns:
            df['type_list'] = df['problem_type_fondue'].apply(lambda x: [] if x is None else (x if isinstance(x, list) else json.loads(x.replace('{', '[').replace('}', ']'))))
            df['type_list_str'] = df['type_list'].apply(lambda x: str(x))
        else:
            df['type_list'] = [[] for _ in range(len(df))]
            df['type_list_str'] = df['type_list'].apply(lambda x: str(x))
        
        if 'org' in df.columns:
            df['organization_list'] = df['org'].apply(lambda x: [] if x is None else (x if isinstance(x, list) else json.loads(x.replace('{', '[').replace('}', ']'))))
            df['organization_list_str'] = df['organization_list'].apply(lambda x: str(x))
        else:
            df['organization_list'] = [[] for _ in range(len(df))]
            df['organization_list_str'] = df['organization_list'].apply(lambda x: str(x))
        
        # Fill missing district information
        df['district'] = df['district'].fillna('à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸')
        
        return df
        
    except Exception as e:
        st.error(f"Error querying database: {e}")
        if conn:
            conn.close()
        return pd.DataFrame()

# Function to load rainfall data
@st.cache_data(ttl=300)
def load_rainfall_data():
    try:
        # Try to load rainfall data
        rainfall_file = "data_and_rain.csv"
        if os.path.exists(rainfall_file):
            rain_df = pd.read_csv(rainfall_file, nrows=1000)
            return rain_df
        else:
            st.warning("Rainfall data file not found.")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"Error loading rainfall data: {e}")
        return pd.DataFrame()

# Load the data
try:
    df = load_data()
    rain_df = load_rainfall_data()
    
    if df.empty:
        st.error("No data found in the database. Please make sure the Airflow DAG to fetch data has been run.")
        st.stop()
    st.success("Data loaded successfully!")
except Exception as e:
    st.error(f"Error loading data: {e}")
    # Create empty dataframe for demonstration
    df = pd.DataFrame()
    st.stop()

# Display raw data with toggle
with st.expander("Show raw data"):
    st.dataframe(df)

# Create tabs for different analyses
tab1, tab_map, tab2, tab3, tab4, tab_rain, tab_model = st.tabs(["Overview", "Map Visualization", "Issue Analysis", "Response Time", "Text Analysis", "Rainfall Analysis", "Model Prediction"])

with tab1:
    st.header("Overview of Reported Issues")
    
    # col1, col2 = st.columns(2)
    
   
        # Count issues by status
    status_counts = df['state'].value_counts().reset_index()
    status_counts.columns = ['Status', 'Count']
    
    fig = px.pie(status_counts, values='Count', names='Status', 
                title='Distribution of Issue Status',
                color_discrete_sequence=px.colors.qualitative.Set3)
    fig.update_traces(textposition='inside', textinfo='percent+label')
    st.plotly_chart(fig, use_container_width=True)
    
    # with col2:
    #     # Issues over time
    #     df_time = df.copy()
    #     df_time['date'] = df_time['timestamp'].dt.date  # à¹à¸ªà¸”à¸‡à¹€à¸‰à¸žà¸²à¸°à¸§à¸±à¸™à¸—à¸µà¹ˆ à¹„à¸¡à¹ˆà¸£à¸§à¸¡à¹€à¸§à¸¥à¸²
    #     daily_counts = df_time.groupby('date').size().reset_index(name='count')

    #     fig = px.line(daily_counts, x='date', y='count', 
    #                 title='Number of Reported Issues by Day',
    #                 labels={'count': 'Number of Issues', 'date': 'Date'})
    #     fig.update_layout(xaxis_tickangle=-45)
    #     # à¸šà¸±à¸‡à¸„à¸±à¸šà¹ƒà¸«à¹‰à¹à¸à¸™ Y à¹€à¸£à¸´à¹ˆà¸¡à¸ˆà¸²à¸ 0
    #     fig.update_yaxes(rangemode="tozero")
    #     st.plotly_chart(fig, use_container_width=True)
    
    # Geographic distribution
    st.subheader("Geographic Distribution of Issues")
    
    district_counts = df['district'].value_counts().reset_index()
    district_counts.columns = ['District', 'Count']
    district_counts = district_counts.sort_values('Count', ascending=False)
    
    fig = px.bar(district_counts.head(15), x='District', y='Count',
                title='Top 15 Districts by Number of Issues',
                color='Count', color_continuous_scale='Viridis')
    fig.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("Analysis of Issue Types")
    
    # Extract all unique issue types
    all_types = [item for sublist in df['type_list'] for item in sublist]
    type_counts = Counter(all_types)
    
    # Prepare data for visualization
    issue_df = pd.DataFrame.from_dict(type_counts, orient='index').reset_index()
    issue_df.columns = ['Issue Type', 'Count']
    issue_df = issue_df.sort_values('Count', ascending=False)
    
    # Display issues by type
    st.subheader("Most Common Issue Types")
    
    fig = px.bar(issue_df.head(10), x='Issue Type', y='Count',
                title='Top 10 Issue Types Reported',
                color='Count', color_continuous_scale='Reds')
    st.plotly_chart(fig, use_container_width=True)
    
    # Organizations responsible for issues
    st.subheader("Organizations Handling Issues")
    
    all_orgs = [item for sublist in df['organization_list'] for item in sublist if item != 'à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸']
    org_counts = Counter(all_orgs)
    
    org_df = pd.DataFrame.from_dict(org_counts, orient='index').reset_index()
    org_df.columns = ['Organization', 'Count']
    org_df = org_df.sort_values('Count', ascending=False)
    
    fig = px.bar(org_df.head(10), x='Organization', y='Count',
                title='Top 10 Organizations Handling Issues',
                color='Count', color_continuous_scale='Blues')
    fig.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig, use_container_width=True)
    
    # Type and Organization relationship
    st.subheader("Relationship Between Issue Type and Organization")
    
    # Get top 5 issue types
    top_types = issue_df.head(5)['Issue Type'].tolist()
    
    # Filter for these top types
    filtered_data = []
    for i, row in df.iterrows():
        for issue_type in row['type_list']:
            if issue_type in top_types:
                for org in row['organization_list']:
                    filtered_data.append({'Issue Type': issue_type, 'Organization': org})
    
    if filtered_data:
        type_org_df = pd.DataFrame(filtered_data)
        type_org_counts = type_org_df.groupby(['Issue Type', 'Organization']).size().reset_index(name='Count')
        type_org_counts = type_org_counts.sort_values(['Issue Type', 'Count'], ascending=[True, False])
        
        # Keep top 3 organizations for each issue type
        top_orgs_per_type = []
        for issue_type in top_types:
            top_for_type = type_org_counts[type_org_counts['Issue Type'] == issue_type].head(3)
            top_orgs_per_type.append(top_for_type)
        
        top_org_df = pd.concat(top_orgs_per_type)
        
        fig = px.bar(top_org_df, x='Issue Type', y='Count', color='Organization',
                    title='Top Organizations Handling the Most Common Issue Types',
                    barmode='group')
        st.plotly_chart(fig, use_container_width=True)

with tab3:
    st.header("Response Time Analysis")
    
    # Basic statistics on resolution time
    st.subheader("Resolution Time Statistics (Days)")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Average", f"{df['resolution_time_days'].mean():.1f} days")
    with col2:
        st.metric("Median", f"{df['resolution_time_days'].median():.1f} days")
    with col3:
        st.metric("Minimum", f"{df['resolution_time_days'].min():.1f} days")
    with col4:
        st.metric("Maximum", f"{df['resolution_time_days'].max():.1f} days")
    
    # Distribution of resolution times
    st.subheader("Distribution of Resolution Times")
    
    fig = px.histogram(df, x='resolution_time_days', nbins=30,
                      title='Distribution of Resolution Times in Days',
                      labels={'resolution_time_days': 'Resolution Time (Days)'},
                      color_discrete_sequence=['darkblue'])
    fig.update_layout(bargap=0.1)
    st.plotly_chart(fig, use_container_width=True)
    
    # Resolution time by issue type
    st.subheader("Average Resolution Time by Issue Type")
    
    # Prepare data for this visualization
    issue_resolution_data = []
    for i, row in df.iterrows():
        for issue_type in row['type_list']:
            issue_resolution_data.append({
                'Issue Type': issue_type,
                'Resolution Time (Days)': row['resolution_time_days']
            })
    
    issue_resolution_df = pd.DataFrame(issue_resolution_data)
    avg_resolution_by_type = issue_resolution_df.groupby('Issue Type')['Resolution Time (Days)'].mean().reset_index()
    avg_resolution_by_type = avg_resolution_by_type.sort_values('Resolution Time (Days)', ascending=False)
    
    fig = px.bar(avg_resolution_by_type.head(10), x='Issue Type', y='Resolution Time (Days)',
                title='Average Resolution Time by Issue Type (Top 10 Slowest)',
                color='Resolution Time (Days)', color_continuous_scale='RdYlGn_r')
    st.plotly_chart(fig, use_container_width=True)
    
    # Resolution time by organization
    st.subheader("Average Resolution Time by Organization")
    
    org_resolution_data = []
    for i, row in df.iterrows():
        for org in row['organization_list']:
            if org != 'à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸':
                org_resolution_data.append({
                    'Organization': org,
                    'Resolution Time (Days)': row['resolution_time_days']
                })
    
    org_resolution_df = pd.DataFrame(org_resolution_data)
    avg_resolution_by_org = org_resolution_df.groupby('Organization')['Resolution Time (Days)'].mean().reset_index()
    avg_resolution_by_org = avg_resolution_by_org.sort_values('Resolution Time (Days)', ascending=False)
    
    fig = px.bar(avg_resolution_by_org.head(10), x='Organization', y='Resolution Time (Days)',
                title='Average Resolution Time by Organization (Top 10 Slowest)',
                color='Resolution Time (Days)', color_continuous_scale='RdYlGn_r')
    fig.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig, use_container_width=True)

with tab4:
    st.header("Text Analysis of Issue Comments")
    
    # Word cloud of comments - only if libraries are available
    st.subheader("Word Cloud of Issue Comments")
    
    # Check if required libraries are available
    if not nltk_available or not pythainlp_available:
        st.warning("Cannot create word cloud: Required libraries (WordCloud, NLTK, or PythaiNLP) are not available.")
        st.info("To enable full text analysis features, please install the required libraries:")
        st.code("pip install wordcloud nltk pythainlp")
    
    # Check if comments are available
    elif 'description' in df.columns and not df['description'].dropna().empty:
        # Combine all comments
        all_comments = ' '.join(df['description'].dropna().astype(str))
        
        try:
            # Use pythainlp for Thai word tokenization
            tokens = word_tokenize(all_comments, engine='newmm')
            
            # Get Thai stopwords
            try:
                thai_stops = list(thai_stopwords())
            except:
                thai_stops = []
            
            # Add custom stopwords
            custom_stops = [
                'à¹„à¸¡à¹ˆ', 'à¹ƒà¸«à¹‰', 'à¹à¸¥à¹‰à¸§', 'à¹€à¸›à¹‡à¸™', 'à¸¡à¸µ', 'à¸à¸²à¸£', 'à¸‚à¸­à¸‡', 'à¸à¹‡', 'à¸—à¸µà¹ˆ', 'à¹„à¸”à¹‰', 'à¸§à¹ˆà¸²', 'à¸ˆà¸°',
                'à¹ƒà¸™', 'à¹à¸•à¹ˆ', 'à¹à¸¥à¸°', 'à¸«à¸£à¸·à¸­', 'à¸¡à¸²à¸', 'à¸à¸±à¸š', 'à¸ˆà¸²à¸', 'à¸–à¹‰à¸²', 'à¸­à¸¢à¸¹à¹ˆ', 'à¸­à¸¢à¹ˆà¸²à¸‡', 'à¸‹à¸¶à¹ˆà¸‡',
                'à¸•à¹‰à¸­à¸‡', 'à¸•à¸²à¸¡', 'à¸«à¸²à¸', 'à¹€à¸žà¸·à¹ˆà¸­', 'à¹‚à¸”à¸¢', 'à¹€à¸¡à¸·à¹ˆà¸­', 'à¹€à¸žà¸£à¸²à¸°', 'à¸™à¸µà¹‰', 'à¸™à¸±à¹‰à¸™', 'à¸ˆà¸¶à¸‡',
                'à¸¢à¸±à¸‡', 'à¹à¸šà¸š', 'à¸—à¸±à¹‰à¸‡', 'à¹€à¸„à¸¢', 'à¸à¸§à¹ˆà¸²', 'à¸­à¸µà¸', 'à¸•à¹ˆà¸­', 'à¹†', '1', '2', '3', '4', '5',
                'à¸„à¸£à¸±à¸š', 'à¸„à¹ˆà¸°', 'à¸™à¹ˆà¸²', 'à¸¡à¸±à¸™', 'à¸à¸—à¸¡', 'à¸à¸£à¸¸à¸‡à¹€à¸—à¸žà¸¡à¸«à¸²à¸™à¸„à¸£'
            ]
            stopwords_list = set(thai_stops + custom_stops)
            
            # Filter out stopwords
            filtered_tokens = [token for token in tokens if token not in stopwords_list and len(token) > 1]
            
            # Create new text after filtering
            filtered_text = ' '.join(filtered_tokens)
            
            # Let user choose word cloud type
            cloud_type = st.radio(
                "Choose Word Cloud Type:",
                ["Classic", "Treemap (Rectangle)"]
            )
            
            if cloud_type == "Classic":
                # Create classic word cloud
                try:
                    # Find Thai font
                    thai_font = None
                    for font in fm.fontManager.ttflist:
                        if any(name in font.name.lower() for name in ['thai', 'tahoma', 'sarabun', 'angsana']):
                            thai_font = fm.findfont(fm.FontProperties(family=font.name))
                            break
                    
                    # Create word cloud
                    wordcloud = WordCloud(
                        font_path=thai_font,
                        width=800, 
                        height=400,
                        background_color='white',
                        stopwords=stopwords_list,
                        max_words=100,
                        contour_width=3,
                        contour_color='steelblue',
                        regexp=r"[^\s]+"  # Help support Thai language
                    ).generate(filtered_text)
                    
                    # Display word cloud
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.imshow(wordcloud, interpolation='bilinear')
                    ax.axis('off')
                    st.pyplot(fig)
                except Exception as e:
                    st.error(f"Error creating word cloud: {e}")
                
            else:
                # Create treemap word cloud
                st.subheader("Word Treemap")
                
                # Count frequency of each word
                word_counts = Counter(filtered_tokens)
                
                try:
                    # Import squarify for treemap visualization
                    import squarify
                    
                    # Select top 30 most frequent words
                    top_words = dict(word_counts.most_common(30))
                    
                    # Create treemap
                    fig, ax = plt.subplots(figsize=(12, 8))
                    
                    # Set colors
                    colors = plt.cm.viridis(np.linspace(0, 1, len(top_words)))
                    
                    # Create treemap
                    squarify.plot(
                        sizes=list(top_words.values()),
                        label=list(top_words.keys()),
                        alpha=0.8,
                        color=colors,
                        ax=ax,
                        text_kwargs={'fontproperties': font_prop} if font_prop else {}
                    )
                    
                    # Customize graph
                    plt.axis('off')
                    plt.title('Most Frequent Words in Issue Comments')
                    
                    # Show treemap
                    st.pyplot(fig)
                except ImportError:
                    st.error("squarify library not found. Please install with: pip install squarify")
                except Exception as e:
                    st.error(f"Error creating treemap: {e}")
        except Exception as e:
            st.error(f"Error in text processing: {e}")
    
    else:
        st.warning("No comment data found in the dataset")
    
    # Show most common words as bar chart
    st.subheader("Most Common Words in Issue Comments")
    
    try:
        if pythainlp_available and 'description' in df.columns and not df['description'].dropna().empty:
            # Tokenize and count words
            all_tokens = []
            for comment in df['description'].dropna():
                try:
                    tokens = word_tokenize(str(comment), engine='newmm')
                    all_tokens.extend([token for token in tokens if token not in stopwords_list and len(token) > 1])
                except:
                    continue
            
            word_counts = Counter(all_tokens)
            
            # Convert to DataFrame
            word_df = pd.DataFrame(word_counts.most_common(20), columns=['Word', 'Count'])
            
            fig = px.bar(word_df, x='Word', y='Count',
                        title='Most Frequent Words in Issue Comments',
                        color='Count', color_continuous_scale='Viridis')
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"Error analyzing frequent words: {e}")

with tab_map:
    st.header("Geographic Distribution of Issues")
    
    # Filter out rows with missing coordinates
    map_df = df.dropna(subset=['latitude', 'longitude'])
    
    if not map_df.empty:
        # Create a column for hover information
        map_df['hover_text'] = map_df.apply(
            lambda row: f"ID: {row['message_id']}<br>" +
                       f"Type: {', '.join(row['type_list'])}<br>" +
                       f"District: {row['district']}<br>" +
                       f"Status: {row['state']}<br>" +
                       f"Reported: {row['timestamp'].strftime('%Y-%m-%d')}", 
            axis=1
        )
        
        # Let user filter by issue type
        all_types = list(set([item for sublist in map_df['type_list'].tolist() for item in sublist]))
        selected_types = st.multiselect(
            "Filter by issue type:", 
            options=['All'] + sorted(all_types),
            default=['All']
        )
        
        # Filter data based on selection
        if selected_types and 'All' not in selected_types:
            filtered_map_df = map_df[map_df['type_list'].apply(lambda x: any(item in selected_types for item in x))]
        else:
            filtered_map_df = map_df
        
        # Color by status
        st.subheader("Issues Mapped by Location")
        
        fig = px.scatter_mapbox(
            filtered_map_df,
            lat="latitude", 
            lon="longitude",
            color="state",
            hover_name="message_id",
            hover_data=["district", "timestamp"],
            custom_data=["hover_text"],
            size_max=15,
            zoom=10,
            height=600,
            mapbox_style="carto-positron"
        )
        
        # Improve hover information
        fig.update_traces(
            hovertemplate="%{customdata[0]}"
        )
        
        # Update layout
        fig.update_layout(
            margin={"r":0,"t":0,"l":0,"b":0},
            legend_title_text='Issue Status'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Add a heatmap view option
        st.subheader("Issue Density Heatmap")
        
        fig2 = px.density_mapbox(
            filtered_map_df, 
            lat='latitude', 
            lon='longitude', 
            z='resolution_time_days',
            radius=20,
            center=dict(lat=13.75, lon=100.5),
            zoom=10,
            mapbox_style="carto-positron",
            height=600,
            title="Heatmap of Issue Density and Resolution Time",
            opacity=0.8,
            color_continuous_scale="Viridis"
        )
        
        st.plotly_chart(fig2, use_container_width=True)
        
        # Add district-based choropleth map
        st.subheader("Issues by District")
        
        # Count issues by district
        district_counts = filtered_map_df.groupby('district').size().reset_index(name='count')
        
        # Create a simple bar chart of districts
        fig3 = px.bar(
            district_counts.sort_values('count', ascending=False),
            x='district',
            y='count',
            title="Issue Count by District",
            color='count',
            color_continuous_scale="Reds"
        )
        
        fig3.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig3, use_container_width=True)
        
    else:
        st.error("No geographic coordinates found in the data. Cannot display map.")

# New tab for rainfall analysis
with tab_rain:
    st.header("Rainfall Data Analysis")
    
    if rain_df.empty:
        st.error("No rainfall data available.")
    else:
        st.success(f"Loaded rainfall data with {len(rain_df)} records")
        
        with st.expander("Show rainfall data"):
            st.dataframe(rain_df)
        
        st.subheader("Rainfall Statistics")
        
        # Display basic rainfall statistics
        rainfall_stats = pd.DataFrame({
            'Statistic': ['Min', 'Max', 'Mean', 'Median'],
            'MinRain': [rain_df['MinRain'].min(), rain_df['MinRain'].max(), 
                        rain_df['MinRain'].mean(), rain_df['MinRain'].median()],
            'MaxRain': [rain_df['MaxRain'].min(), rain_df['MaxRain'].max(), 
                        rain_df['MaxRain'].mean(), rain_df['MaxRain'].median()],
            'AvgRain': [rain_df['AvgRain'].min(), rain_df['AvgRain'].max(), 
                        rain_df['AvgRain'].mean(), rain_df['AvgRain'].median()]
        })
        
        st.table(rainfall_stats)
        
        # Visualization of rainfall data
        st.subheader("Rainfall Distribution by Month")
        
        # if 'MONTH' in rain_df.columns:
        #     # Create a month-based rainfall visualization
        #     monthly_rain = rain_df.groupby('MONTH')['AvgRain'].mean().reset_index()
            
        #     fig = px.line(monthly_rain, x='MONTH', y='AvgRain',
        #                  title='Average Rainfall by Month',
        #                  labels={'AvgRain': 'Average Rainfall', 'MONTH': 'Month'},
        #                  markers=True)
        #     fig.update_layout(xaxis=dict(tickmode='linear'))
        #     st.plotly_chart(fig, use_container_width=True)
        
        # Compare rainfall with issue frequency
        st.subheader("Relationship Between Rainfall and Issue Reporting")
        
        # Check if we can merge data based on district/province
        if 'district' in df.columns and 'PROV_T' in rain_df.columns:
            try:
                # Convert columns to same case for easier matching
                df_copy = df.copy()
                rain_copy = rain_df.copy()
                
                df_copy['district_lower'] = df_copy['district'].str.lower()
                rain_copy['PROV_T_lower'] = rain_copy['PROV_T'].str.lower()
                
                # Count issues by district
                district_issues = df_copy.groupby('district_lower').size().reset_index(name='issue_count')
                
                # Merge with rainfall data
                merged_data = pd.merge(
                    district_issues, 
                    rain_copy,
                    left_on='district_lower',
                    right_on='PROV_T_lower',
                    how='inner'
                )
                
                if not merged_data.empty:
                    # Create a scatter plot
                    fig = px.scatter(
                        merged_data, 
                        x='AvgRain', 
                        y='issue_count',
                        size='issue_count',
                        color='AvgRain',
                        hover_name='PROV_T',
                        labels={
                            'AvgRain': 'Average Rainfall',
                            'issue_count': 'Number of Issues Reported'
                        },
                        title='Relationship Between Average Rainfall and Number of Issues Reported'
                    )
                    
                    # Add trendline
                    fig.update_traces(marker=dict(line=dict(width=1, color='DarkSlateGray')))
                    fig.update_layout(coloraxis_colorbar=dict(title='Avg Rainfall'))
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Calculate correlation
                    correlation = merged_data['AvgRain'].corr(merged_data['issue_count'])
                    st.metric("Correlation between Rainfall and Issues", f"{correlation:.3f}")
                    
                    if correlation > 0.3:
                        st.info("There appears to be a positive correlation between rainfall and issue reporting.")
                    elif correlation < -0.3:
                        st.info("There appears to be a negative correlation between rainfall and issue reporting.")
                    else:
                        st.info("There does not appear to be a strong correlation between rainfall and issue reporting.")
                else:
                    st.warning("Could not match districts between datasets. Check that names are consistent.")
            except Exception as e:
                st.error(f"Error analyzing rainfall correlation: {e}")
                
        # Rainfall by province/district
        # if 'PROV_T' in rain_df.columns:
        #     st.subheader("Average Rainfall by Province")
            
        #     # Group by province
        #     province_rain = rain_df.groupby('PROV_T')['AvgRain'].mean().reset_index()
        #     province_rain = province_rain.sort_values('AvgRain', ascending=False)
            
        #     fig = px.bar(
        #         province_rain,
        #         x='PROV_T',
        #         y='AvgRain',
        #         title='Average Rainfall by Province',
        #         color='AvgRain',
        #         color_continuous_scale='Blues'
        #     )
            
        #     fig.update_layout(xaxis_tickangle=-45)
        #     st.plotly_chart(fig, use_container_width=True)
        
        # Analyze peak rainfall months
        if 'MONTH' in rain_df.columns and 'AvgRain' in rain_df.columns:
            st.subheader("Peak Rainfall Months")
            
            # Get average rainfall by month
            monthly_avg = rain_df.groupby('MONTH')['AvgRain'].mean().reset_index()
            monthly_avg = monthly_avg.sort_values('AvgRain', ascending=False)
            
            # Map month numbers to names
            month_names = {
                1: 'January', 2: 'February', 3: 'March', 4: 'April',
                5: 'May', 6: 'June', 7: 'July', 8: 'August',
                9: 'September', 10: 'October', 11: 'November', 12: 'December'
            }
            
            monthly_avg['Month Name'] = monthly_avg['MONTH'].map(month_names)
            
            # Show peak rainfall months
            st.markdown("#### Months with Highest Average Rainfall")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Display top 3 months with highest rainfall
                st.write(f"à¸ˆà¸³à¸™à¸§à¸™à¹€à¸”à¸·à¸­à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {len(monthly_avg)}")
                monthly_by_month = monthly_avg.sort_values('MONTH')
                st.table(monthly_by_month[['Month Name', 'AvgRain']])
            
            with col2:
                # Create a simple visualization for peak months
                fig = px.bar(
                    monthly_avg.head(12),
                    x='Month Name',
                    y='AvgRain',
                    color='AvgRain',
                    color_continuous_scale='Blues',
                    title='Months with Highest Rainfall'
                )
                st.plotly_chart(fig, use_container_width=True)
# à¹€à¸žà¸´à¹ˆà¸¡à¹ƒà¸™à¸ªà¹ˆà¸§à¸™ tab_rain

        # à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¹‚à¸„à¹‰à¸”à¸ªà¹ˆà¸§à¸™à¹à¸œà¸™à¸—à¸µà¹ˆà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹ƒà¸™ tab_rain
        st.subheader("à¹à¸œà¸™à¸—à¸µà¹ˆà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ (à¹ƒà¸Šà¹‰à¸žà¸´à¸à¸±à¸”à¸ˆà¸²à¸à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ coords à¹‚à¸”à¸¢à¸•à¸£à¸‡)")

        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ coords à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
        if 'coords' in rain_df.columns:
            # à¹à¸¢à¸à¸žà¸´à¸à¸±à¸”à¸ˆà¸²à¸à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ coords
            rain_df_with_coords = rain_df.copy()
            
            try:
                # à¹à¸¢à¸à¸„à¹ˆà¸² longitude à¹à¸¥à¸° latitude à¸ˆà¸²à¸à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ coords
                # à¸£à¸¹à¸›à¹à¸šà¸šà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡: "100.53084,13.81865"
                rain_df_with_coords[['longitude', 'latitude']] = rain_df_with_coords['coords'].str.split(',', expand=True).astype(float)
                
                # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸žà¸´à¸à¸±à¸”à¸—à¸µà¹ˆà¸ªà¸à¸±à¸”à¹„à¸”à¹‰
                # st.write("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸™à¸—à¸µà¹ˆà¸¡à¸µà¸žà¸´à¸à¸±à¸”:", len(rain_df_with_coords), "à¹à¸–à¸§")
                # st.dataframe(rain_df_with_coords[['coords', 'longitude', 'latitude', 'AvgRain']].head())
                
                # à¸ªà¸£à¹‰à¸²à¸‡ heatmap à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸žà¸´à¸à¸±à¸”à¹‚à¸”à¸¢à¸•à¸£à¸‡
                fig = px.density_mapbox(
                    rain_df_with_coords,
                    lat="latitude", 
                    lon="longitude", 
                    z="AvgRain",
                    radius=15,  # à¸›à¸£à¸±à¸šà¸£à¸±à¸¨à¸¡à¸µà¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
                    center=dict(lat=13.75, lon=100.5),  # à¸žà¸´à¸à¸±à¸”à¸à¸¥à¸²à¸‡à¸‚à¸­à¸‡à¸à¸£à¸¸à¸‡à¹€à¸—à¸žà¸¯
                    zoom=9,
                    mapbox_style="carto-positron",
                    height=600,
                    opacity=0.7,
                    color_continuous_scale="RdBu_r",
                    title="à¹à¸œà¸™à¸—à¸µà¹ˆà¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸¡à¸‚à¸­à¸‡à¸à¸™à¸•à¸à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸žà¸´à¸à¸±à¸”à¸ˆà¸£à¸´à¸‡"
                )
                
                # à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ layout
                fig.update_layout(
                    margin={"r":0, "t":30, "l":0, "b":0},
                    coloraxis_colorbar=dict(
                        title="à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢"
                    )
                )
                
                # à¹à¸ªà¸”à¸‡à¹à¸œà¸™à¸—à¸µà¹ˆ
                st.plotly_chart(fig, use_container_width=True)
                
                # à¹€à¸žà¸´à¹ˆà¸¡à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸•à¸²à¸¡à¹€à¸‚à¸• - à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸•
                st.subheader("à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆà¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”/à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸” (à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¹€à¸‚à¸•)")
                
                # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹€à¸‚à¸•à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
                district_column = None
                if 'district' in rain_df_with_coords.columns:
                    district_column = 'district'
                elif 'à¹€à¸‚à¸•' in rain_df_with_coords.columns:
                    district_column = 'à¹€à¸‚à¸•'
                
                if district_column:
                    # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸•
                    district_avg_rain = rain_df_with_coords.groupby(district_column)['AvgRain'].mean().reset_index()
                    district_avg_rain.columns = ['à¹€à¸‚à¸•', 'à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢']
                    
                    # à¸„à¸³à¸™à¸§à¸“à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸•
                    district_count = rain_df_with_coords.groupby(district_column).size().reset_index()
                    district_count.columns = ['à¹€à¸‚à¸•', 'à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥']
                    
                    # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™
                    district_stats = pd.merge(district_avg_rain, district_count, on='à¹€à¸‚à¸•')
                    
                    # à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸šà¸•à¸²à¸¡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢
                    district_stats_desc = district_stats.sort_values('à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢', ascending=False)
                    district_stats_asc = district_stats.sort_values('à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢')
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # à¹à¸ªà¸”à¸‡à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸à¸™à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸” 10 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸
                        st.write("à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸à¸™à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸” 10 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸:")
                        st.dataframe(district_stats_desc.head(10))
                    
                    with col2:
                        # à¹à¸ªà¸”à¸‡à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸à¸™à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸” 10 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸
                        st.write("à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸à¸™à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸” 10 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸:")
                        st.dataframe(district_stats_asc.head(10))
                    
                    # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¹à¸—à¹ˆà¸‡à¹à¸ªà¸”à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸• (Top 15)
                    st.subheader("à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸• (15 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸)")
                    
                    fig_bar = px.bar(
                        district_stats_desc.head(15),
                        x='à¹€à¸‚à¸•',
                        y='à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        color='à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        text='à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥',  # à¹à¸ªà¸”à¸‡à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸šà¸™à¹à¸•à¹ˆà¸¥à¸°à¹à¸—à¹ˆà¸‡
                        color_continuous_scale="Blues",
                        height=500,
                        title="à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸ªà¸¹à¸‡à¸—à¸µà¹ˆà¸ªà¸¸à¸” 15 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸"
                    )
                    
                    fig_bar.update_layout(xaxis_tickangle=-45)
                    fig_bar.update_traces(texttemplate='%{text} à¸‚à¹‰à¸­à¸¡à¸¹à¸¥', textposition='outside')
                    
                    st.plotly_chart(fig_bar, use_container_width=True)
                    
                else:
                    st.warning("à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹€à¸‚à¸• (district) à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸ˆà¸¶à¸‡à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¹€à¸‚à¸•à¹„à¸”à¹‰")
                    
            except Exception as e:
                st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹à¸¢à¸à¸žà¸´à¸à¸±à¸”: {e}")
                st.write("à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸„à¹ˆà¸²à¹ƒà¸™à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ coords:")
                st.write(rain_df['coords'].head())
        else:
            st.error("à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'coords' à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸™")

        # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸™à¹‰à¸³à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—
        st.header("à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸™à¹‰à¸³à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²")

        if not rain_df.empty and not df.empty:
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ district à¹ƒà¸™à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
            if 'district' in df.columns and 'district' in rain_df.columns:
                # à¸›à¸£à¸±à¸šà¹ƒà¸«à¹‰à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¹€à¸›à¹‡à¸™à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™
                df_copy = df.copy()
                rain_copy = rain_df.copy()
                
                # à¹à¸›à¸¥à¸‡à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸žà¸´à¸¡à¸žà¹Œà¹€à¸¥à¹‡à¸à¹à¸¥à¸°à¸•à¸±à¸”à¸Šà¹ˆà¸­à¸‡à¸§à¹ˆà¸²à¸‡à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸ˆà¸±à¸šà¸„à¸¹à¹ˆà¹„à¸”à¹‰à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                df_copy['district_lower'] = df_copy['district'].str.lower().str.strip()
                rain_copy['district_lower'] = rain_copy['district'].str.lower().str.strip()
                
                # à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸•
                issue_counts_by_district = []
                
                # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸•
                for i, row in df_copy.iterrows():
                    district = row['district_lower']
                    for issue_type in row['type_list']:
                        issue_counts_by_district.append({
                            'district': district,
                            'issue_type': issue_type
                        })
                
                # à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ DataFrame
                issue_df = pd.DataFrame(issue_counts_by_district)
                
                # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸•
                district_issue_counts = issue_df.groupby(['district', 'issue_type']).size().reset_index(name='count')
                
                # à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸±à¸à¸«à¸²à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸™
                merged_data = pd.merge(
                    district_issue_counts,
                    rain_copy,
                    left_on='district',
                    right_on='district_lower',
                    how='inner'
                )
                
                # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸”à¹‰à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
                if merged_data.empty:
                    st.warning("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸”à¹‰ à¸¥à¸­à¸‡à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‚à¸•à¹ƒà¸™à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
                    
                    # à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸·à¹ˆà¸­à¸”à¸µà¸šà¸±à¸
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸±à¸à¸«à¸² (5 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸):")
                        st.write(df_copy['district_lower'].value_counts().head())
                    with col2:
                        st.write("à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸™ (5 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸):")
                        st.write(rain_copy['district_lower'].value_counts().head())
                else:
                    st.success(f"à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ! à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸™ {len(merged_data)} à¸£à¸²à¸¢à¸à¸²à¸£")
                    
                    # à¸«à¸²à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸à¸™
                    rain_columns = [col for col in merged_data.columns if any(word in col.lower() for word in ['rain', 'à¸à¸™', 'precipitation'])]
                    
                    if not rain_columns:
                        st.warning("à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
                        st.write("à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹à¸¥à¹‰à¸§:")
                        st.write(merged_data.columns.tolist())
                        
                        # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸à¸™ à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸”à¸µà¸Ÿà¸­à¸¥à¸•à¹Œ
                        rain_columns = ['AvgRain', 'MinRain', 'MaxRain']
                    
                    # à¹€à¸¥à¸·à¸­à¸à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸à¸™à¸—à¸µà¹ˆà¸ˆà¸°à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ
                    selected_rain_column = st.selectbox(
                        "à¹€à¸¥à¸·à¸­à¸à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ:",
                        options=rain_columns,
                        index=0 if 'AvgRain' in rain_columns else 0
                    )
                    
                    # à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ
                    analysis_type = st.radio(
                        "à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ:",
                        options=["à¹à¸¢à¸à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²", "à¸ à¸²à¸žà¸£à¸§à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"],
                        horizontal=True
                    )
                    
                    if analysis_type == "à¹à¸¢à¸à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²":
                        # à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸žà¸šà¸šà¹ˆà¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸” 5 à¸­à¸±à¸™à¸”à¸±à¸šà¹à¸£à¸
                        top_issues = merged_data['issue_type'].value_counts().head(5).index.tolist()
                        
                        # à¸à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‰à¸žà¸²à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸žà¸šà¸šà¹ˆà¸­à¸¢
                        filtered_data = merged_data[merged_data['issue_type'].isin(top_issues)]
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ
                        st.subheader(f"à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ {selected_rain_column} à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—")
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡ Scatter plot à¹à¸¢à¸à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²
                        fig = px.scatter(
                            filtered_data,
                            x=selected_rain_column,
                            y='count',
                            color='issue_type',
                            hover_name='district_x',  # à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¹€à¸›à¹‡à¸™ hover
                            hover_data=[selected_rain_column, 'count'],
                            labels={
                                selected_rain_column: f'à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ ({selected_rain_column})',
                                'count': 'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²',
                                'issue_type': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²'
                            },
                            title=f'à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ ({selected_rain_column}) à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—',
                            trendline='ols'  # à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸ªà¹‰à¸™à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²
                        st.subheader("à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ")
                        
                        correlation_data = []
                        for issue in top_issues:
                            issue_data = filtered_data[filtered_data['issue_type'] == issue]
                            if len(issue_data) >= 5:  # à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 5 à¸ˆà¸¸à¸”à¸ˆà¸¶à¸‡à¸ˆà¸°à¸„à¸³à¸™à¸§à¸“
                                corr = issue_data[selected_rain_column].corr(issue_data['count'])
                                correlation_data.append({
                                    'à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²': issue,
                                    'à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ': corr,
                                    'à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ': abs(corr)
                                })
                        
                        if correlation_data:
                            corr_df = pd.DataFrame(correlation_data)
                            corr_df = corr_df.sort_values('à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ', ascending=False)
                            
                            # à¹à¸ªà¸”à¸‡à¸œà¸¥à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸•à¸²à¸£à¸²à¸‡
                            st.write("à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—")
                            
                            # à¸ªà¸£à¹‰à¸²à¸‡ color map à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ
                            def correlaction_color(val):

                                if val > 0.7:
                                    return 'background-color: #00802b; color: white'  # à¸ªà¸µà¹€à¸‚à¸µà¸¢à¸§à¹€à¸‚à¹‰à¸¡ + à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸‚à¸²à¸§ (à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸šà¸§à¸à¸¡à¸²à¸)
                                elif val > 0.3:
                                    return 'background-color: #4CAF50; color: black'  # à¸ªà¸µà¹€à¸‚à¸µà¸¢à¸§à¸›à¸²à¸™à¸à¸¥à¸²à¸‡ + à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸”à¸³ (à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸šà¸§à¸à¸›à¸²à¸™à¸à¸¥à¸²à¸‡)
                                elif val < -0.7:
                                    return 'background-color: #CC0000; color: white'  # à¸ªà¸µà¹à¸”à¸‡à¹€à¸‚à¹‰à¸¡ + à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸‚à¸²à¸§ (à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸¥à¸šà¸¡à¸²à¸)
                                elif val < -0.3:
                                    return 'background-color: #FF5733; color: black'  # à¸ªà¸µà¹à¸”à¸‡à¸ªà¹‰à¸¡ + à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸”à¸³ (à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸¥à¸šà¸›à¸²à¸™à¸à¸¥à¸²à¸‡)
                                else:
                                    return 'background-color: #E8E8E8; color: black'  # à¸ªà¸µà¹€à¸—à¸²à¸­à¹ˆà¸­à¸™ + à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸”à¸³ (à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸™à¹‰à¸­à¸¢)   
                            
                            # à¹à¸ªà¸”à¸‡à¸•à¸²à¸£à¸²à¸‡à¸žà¸£à¹‰à¸­à¸¡à¸£à¸°à¸šà¸²à¸¢à¸ªà¸µ
                            st.dataframe(corr_df.style.format({
                                'à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ': '{:.3f}'
                            }).applymap(correlaction_color, subset=['à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ']))
                            
                            # à¹à¸ªà¸”à¸‡à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡à¸œà¸¥
                            st.subheader("à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡à¸œà¸¥")
                            
                            # à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸šà¸§à¸à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
                            positive_corr = corr_df[corr_df['à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ'] > 0].sort_values('à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ', ascending=False)
                            if not positive_corr.empty:
                                pos_issue = positive_corr.iloc[0]['à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²']
                                pos_corr = positive_corr.iloc[0]['à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ']
                                
                                if pos_corr > 0.7:
                                    st.success(f"à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸— '{pos_issue}' à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸šà¸§à¸à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸ªà¸¹à¸‡à¸¡à¸²à¸ ({pos_corr:.3f}) à¸à¸±à¸šà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸—à¸™à¸µà¹‰à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸—à¸µà¹ˆà¸ˆà¸°à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¸¡à¸²à¸")
                                elif pos_corr > 0.3:
                                    st.info(f"à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸— '{pos_issue}' à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸šà¸§à¸à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸›à¸²à¸™à¸à¸¥à¸²à¸‡ ({pos_corr:.3f}) à¸à¸±à¸šà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸—à¸™à¸µà¹‰à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸—à¸µà¹ˆà¸ˆà¸°à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¸šà¹‰à¸²à¸‡")
                            
                            # à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸¥à¸šà¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
                            negative_corr = corr_df[corr_df['à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ'] < 0].sort_values('à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ', ascending=True)
                            if not negative_corr.empty:
                                neg_issue = negative_corr.iloc[0]['à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²']
                                neg_corr = negative_corr.iloc[0]['à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ']
                                
                                if neg_corr < -0.7:
                                    st.success(f"à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸— '{neg_issue}' à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸¥à¸šà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸ªà¸¹à¸‡à¸¡à¸²à¸ ({neg_corr:.3f}) à¸à¸±à¸šà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸—à¸™à¸µà¹‰à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸—à¸µà¹ˆà¸ˆà¸°à¸¥à¸”à¸¥à¸‡à¸¡à¸²à¸")
                                elif neg_corr < -0.3:
                                    st.info(f"à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸— '{neg_issue}' à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸¥à¸šà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸›à¸²à¸™à¸à¸¥à¸²à¸‡ ({neg_corr:.3f}) à¸à¸±à¸šà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸›à¸±à¸à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸—à¸™à¸µà¹‰à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸—à¸µà¹ˆà¸ˆà¸°à¸¥à¸”à¸¥à¸‡à¸šà¹‰à¸²à¸‡")
                                    
                            # à¸«à¸²à¸à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™
                            if (positive_corr.empty or positive_corr.iloc[0]['à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ'] <= 0.3) and (negative_corr.empty or negative_corr.iloc[0]['à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ'] >= -0.3):
                                st.warning("à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸¸à¸à¸›à¸£à¸°à¹€à¸ à¸— à¸­à¸²à¸ˆà¸¡à¸µà¸›à¸±à¸ˆà¸ˆà¸±à¸¢à¸­à¸·à¹ˆà¸™à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸´à¸—à¸˜à¸´à¸žà¸¥à¸•à¹ˆà¸­à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™")
                        else:
                            st.warning("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¹ƒà¸™à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ")
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸ªà¹‰à¸™à¹à¸ªà¸”à¸‡à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²
                        # st.subheader("à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸•à¸²à¸¡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™")
                        
                        # # à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™
                        # filtered_data['rain_range'] = pd.cut(
                        #     filtered_data[selected_rain_column],
                        #     bins=5,  # à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™ 5 à¸Šà¹ˆà¸§à¸‡
                        #     labels=["à¸™à¹‰à¸­à¸¢à¸¡à¸²à¸", "à¸™à¹‰à¸­à¸¢", "à¸›à¸²à¸™à¸à¸¥à¸²à¸‡", "à¸¡à¸²à¸", "à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”"]
                        # )
                        
                        # # à¸«à¸²à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™
                        # avg_by_rain = filtered_data.groupby(['rain_range', 'issue_type'])['count'].mean().reset_index()
                        
                        # # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸ªà¹‰à¸™
                        # line_fig = px.line(
                        #     avg_by_rain,
                        #     x='rain_range',
                        #     y='count',
                        #     color='issue_type',
                        #     markers=True,
                        #     labels={
                        #         'rain_range': 'à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™',
                        #         'count': 'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        #         'issue_type': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²'
                        #     },
                        #     title=f'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ ({selected_rain_column})'
                        # )
                        
                        # st.plotly_chart(line_fig, use_container_width=True)
                        
                    else:  # à¸ à¸²à¸žà¸£à¸§à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
                        # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸±à¸à¸«à¸²à¸—à¸¸à¸à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™à¸•à¸²à¸¡à¹€à¸‚à¸•
                        district_total = merged_data.groupby('district_x')[['count', selected_rain_column]].agg({
                            'count': 'sum',
                            selected_rain_column: 'mean'
                        }).reset_index()
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ
                        st.subheader(f"à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ {selected_rain_column} à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”")
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡ Scatter plot à¸ à¸²à¸žà¸£à¸§à¸¡
                        fig = px.scatter(
                            district_total,
                            x=selected_rain_column,
                            y='count',
                            hover_name='district_x',
                            hover_data=[selected_rain_column, 'count'],
                            labels={
                                selected_rain_column: f'à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ ({selected_rain_column})',
                                'count': 'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”'
                            },
                            title=f'à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ ({selected_rain_column}) à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”',
                            trendline='ols'  # à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸ªà¹‰à¸™à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡
                        )
                        
                        # à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸à¸£à¸²à¸Ÿ
                        fig.update_traces(marker=dict(size=10, opacity=0.7))
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸ à¸²à¸žà¸£à¸§à¸¡
                        overall_corr = district_total[selected_rain_column].corr(district_total['count'])
                        
                        # à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸ à¸²à¸žà¸£à¸§à¸¡
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("à¸„à¹ˆà¸²à¸ªà¸«à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸ à¸²à¸žà¸£à¸§à¸¡", f"{overall_corr:.3f}")
                        
                        with col2:
                            if abs(overall_corr) > 0.7:
                                st.success("à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸”à¸±à¸šà¸ªà¸¹à¸‡à¸¡à¸²à¸")
                            elif abs(overall_corr) > 0.5:
                                st.info("à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸”à¸±à¸šà¸ªà¸¹à¸‡")
                            elif abs(overall_corr) > 0.3:
                                st.info("à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸”à¸±à¸šà¸›à¸²à¸™à¸à¸¥à¸²à¸‡")
                            else:
                                st.warning("à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸”à¸±à¸šà¸•à¹ˆà¸³")
                        
                        # à¸­à¸˜à¸´à¸šà¸²à¸¢à¸œà¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ
                        st.subheader("à¸à¸²à¸£à¸•à¸µà¸„à¸§à¸²à¸¡à¸œà¸¥")
                        
                        if overall_corr > 0.7:
                            st.success(f"à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸šà¸§à¸à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸ªà¸¹à¸‡à¸¡à¸²à¸ (r = {overall_corr:.3f}) à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¸¡à¸²à¸")
                        elif overall_corr > 0.3:
                            st.info(f"à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸šà¸§à¸à¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸›à¸²à¸™à¸à¸¥à¸²à¸‡ (r = {overall_corr:.3f}) à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¸šà¹‰à¸²à¸‡")
                        elif overall_corr < -0.7:
                            st.success(f"à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸¥à¸šà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸ªà¸¹à¸‡à¸¡à¸²à¸ (r = {overall_corr:.3f}) à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸¥à¸”à¸¥à¸‡à¸¡à¸²à¸")
                        elif overall_corr < -0.3:
                            st.info(f"à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¹€à¸Šà¸´à¸‡à¸¥à¸šà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸›à¸²à¸™à¸à¸¥à¸²à¸‡ (r = {overall_corr:.3f}) à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” à¸™à¸±à¹ˆà¸™à¸„à¸·à¸­à¹€à¸¡à¸·à¹ˆà¸­à¸à¸™à¸•à¸à¸¡à¸²à¸ à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸¥à¸”à¸¥à¸‡à¸šà¹‰à¸²à¸‡")
                        else:
                            st.warning(f"à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™ (r = {overall_corr:.3f}) à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” à¸­à¸²à¸ˆà¸¡à¸µà¸›à¸±à¸ˆà¸ˆà¸±à¸¢à¸­à¸·à¹ˆà¸™à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸´à¸—à¸˜à¸´à¸žà¸¥à¸•à¹ˆà¸­à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™")
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸ªà¹‰à¸™à¹à¸ªà¸”à¸‡à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™
                        st.subheader("à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸‚à¸­à¸‡à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸•à¸²à¸¡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™")
                        
                        # à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™
                        district_total['rain_range'] = pd.cut(
                            district_total[selected_rain_column],
                            bins=5,  # à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™ 5 à¸Šà¹ˆà¸§à¸‡
                            labels=["à¸™à¹‰à¸­à¸¢à¸¡à¸²à¸", "à¸™à¹‰à¸­à¸¢", "à¸›à¸²à¸™à¸à¸¥à¸²à¸‡", "à¸¡à¸²à¸", "à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”"]
                        )
                        
                        # à¸«à¸²à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™
                        avg_by_rain = district_total.groupby('rain_range')['count'].mean().reset_index()
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸ªà¹‰à¸™
                        bar_fig = px.bar(
                            avg_by_rain,
                            x='rain_range',
                            y='count',
                            color='rain_range',
                            labels={
                                'rain_range': 'à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™',
                                'count': 'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢'
                            },
                            title=f'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ ({selected_rain_column})'
                        )
                        
                        st.plotly_chart(bar_fig, use_container_width=True)
                        
                        # à¹à¸ªà¸”à¸‡à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹à¸¥à¸°à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”/à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”
                        st.subheader("à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¹à¸¥à¸°à¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸ªà¸¹à¸‡à¸ªà¸¸à¸”/à¸•à¹ˆà¸³à¸ªà¸¸à¸”")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            # à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
                            max_rain_district = district_total.sort_values(selected_rain_column, ascending=False).head(5)
                            st.write(f"à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸™ ({selected_rain_column}) à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”:")
                            st.dataframe(max_rain_district[['district_x', selected_rain_column, 'count']])
                        
                        with col2:
                            # à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
                            max_issue_district = district_total.sort_values('count', ascending=False).head(5)
                            st.write("à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸ˆà¸³à¸™à¸§à¸™à¸›à¸±à¸à¸«à¸²à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”:")
                            st.dataframe(max_issue_district[['district_x', selected_rain_column, 'count']])
            else:
                st.warning("à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ district à¹ƒà¸™à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸”à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸™à¸¶à¹ˆà¸‡à¸«à¸£à¸·à¸­à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸Šà¸¸à¸”")
                
                # à¹à¸ªà¸”à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
                col1, col2 = st.columns(2)
                with col1:
                    st.write("à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸±à¸à¸«à¸²:")
                    st.write(df.columns.tolist())
                with col2:
                    st.write("à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸™:")
                    st.write(rain_df.columns.tolist())
        else:
            st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")


with tab_model:
    # à¸ªà¸£à¹‰à¸²à¸‡à¹à¸—à¹‡à¸šà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢
    st.header("à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¸à¸±à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢")

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œ CSV à¸ªà¸³à¸«à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    pred_file = "y_pred_compared.csv"

    if os.path.exists(pred_file):
        # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        try:
            pred_df = pd.read_csv(pred_file, nrows=1000)
            st.success(f"à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢à¸ªà¸³à¹€à¸£à¹‡à¸ˆ! à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {len(pred_df)} à¹à¸–à¸§")
            
            # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
            with st.expander("à¸”à¸¹à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸³à¸™à¸²à¸¢à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡"):
                st.dataframe(pred_df[['comment', 'time_taken', 'predicted_time']].head(10))
            
            # à¸ªà¸£à¹‰à¸²à¸‡à¹à¸—à¹‡à¸šà¸¢à¹ˆà¸­à¸¢à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸•à¹ˆà¸²à¸‡à¹†
            pred_tab1, pred_tab2, pred_tab3, pred_tab4 = st.tabs([
                "à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹‚à¸”à¸¢à¸•à¸£à¸‡", "à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³", "à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸•à¸²à¸¡à¹€à¸‚à¸•", "à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²"
            ])
            
            with pred_tab1:
                st.subheader("à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¸à¸±à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢")
                
                # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿ Scatter plot
                fig = px.scatter(
                    pred_df,
                    x='time_taken',
                    y='predicted_time',
                    hover_data=['comment'],  # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹ƒà¸™à¸à¸²à¸£ hover
                    title='à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¸à¸±à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢',
                    labels={
                        'time_taken': 'à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ˆà¸£à¸´à¸‡ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)',
                        'predicted_time': 'à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)'
                    },
                    opacity=0.7
                )
                
                # à¹€à¸žà¸´à¹ˆà¸¡ line y=x (à¹€à¸ªà¹‰à¸™à¸—à¸³à¸™à¸²à¸¢à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹à¸šà¸š)
                max_val = max(pred_df['time_taken'].max(), pred_df['predicted_time'].max())
                fig.add_trace(
                    go.Scatter(
                        x=[0, max_val],
                        y=[0, max_val],
                        mode='lines',
                        name='à¸—à¸³à¸™à¸²à¸¢à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹à¸šà¸š',
                        line=dict(color='red', dash='dash')
                    )
                )
                
                # à¹€à¸žà¸´à¹ˆà¸¡ trend line
                fig.add_trace(
                    px.scatter(
                        pred_df, 
                        x='time_taken', 
                        y='predicted_time', 
                        trendline='ols'
                    ).data[1]
                )
                
                # à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸à¸£à¸²à¸Ÿ
                fig.update_layout(
                    xaxis=dict(range=[0, max_val]),
                    yaxis=dict(range=[0, max_val])
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                
                # à¸ªà¸£à¹‰à¸²à¸‡à¸®à¸´à¸ªà¹‚à¸•à¹à¸à¸£à¸¡à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§
                hist_fig = go.Figure()
                hist_fig.add_trace(go.Histogram(
                    x=pred_df['time_taken'],
                    name='à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ˆà¸£à¸´à¸‡',
                    opacity=0.7,
                    marker_color='blue'
                ))
                hist_fig.add_trace(go.Histogram(
                    x=pred_df['predicted_time'],
                    name='à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢',
                    opacity=0.7,
                    marker_color='orange'
                ))
                
                hist_fig.update_layout(
                    title="à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹à¸¥à¸°à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢",
                    xaxis_title="à¹€à¸§à¸¥à¸² (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)",
                    yaxis_title="à¸ˆà¸³à¸™à¸§à¸™",
                    barmode='overlay'
                )
                
                st.plotly_chart(hist_fig, use_container_width=True)
                
                # à¸ªà¸£à¹‰à¸²à¸‡ Box plot à¹€à¸žà¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š
                box_data = pd.DataFrame({
                    'à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ˆà¸£à¸´à¸‡': pred_df['time_taken'],
                    'à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢': pred_df['predicted_time']
                })
                
                box_fig = px.box(
                    box_data,
                    points='all',
                    title="à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹à¸¥à¸°à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢"
                )
                
                st.plotly_chart(box_fig, use_container_width=True)
            
            with pred_tab2:
                st.subheader("à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸‚à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢")
                
                # à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™
                pred_df['error'] = pred_df['predicted_time'] - pred_df['time_taken']
                pred_df['abs_error'] = abs(pred_df['error'])
                pred_df['squared_error'] = pred_df['error'] ** 2
                
                # à¸„à¸³à¸™à¸§à¸“ % à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™ (à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ division by zero)
                pred_df['pct_error'] = np.where(
                    pred_df['time_taken'] > 0,
                    (pred_df['error'] / pred_df['time_taken']) * 100,
                    0
                )
                
                # à¸„à¸³à¸™à¸§à¸“à¹€à¸¡à¸•à¸£à¸´à¸à¸•à¹ˆà¸²à¸‡à¹†
                mae = pred_df['abs_error'].mean()
                mse = pred_df['squared_error'].mean()
                rmse = np.sqrt(mse)
                mape = np.abs(pred_df['pct_error']).mean()
                
                # à¹à¸ªà¸”à¸‡à¹€à¸¡à¸•à¸£à¸´à¸à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
                metrics_col1, metrics_col2, metrics_col3, metrics_col4 = st.columns(4)
                with metrics_col1:
                    st.metric("Mean Absolute Error (MAE)", f"{mae:.2f} à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡")
                with metrics_col2:
                    st.metric("Root Mean Squared Error (RMSE)", f"{rmse:.2f} à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡")
                with metrics_col3:
                    st.metric("Mean Absolute Percentage Error (MAPE)", f"{mape:.2f}%")
                with metrics_col4:
                    # à¸„à¸³à¸™à¸§à¸“ R-Squared
                    correlation = np.corrcoef(pred_df['time_taken'], pred_df['predicted_time'])[0, 1]
                    r_squared = correlation ** 2
                    st.metric("R-Squared (RÂ²)", f"{r_squared:.3f}")
                
                # à¹à¸›à¸¥à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸œà¸¥
                if r_squared > 0.7:
                    st.success("à¹à¸šà¸šà¸ˆà¸³à¸¥à¸­à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸”à¸µ (RÂ² > 0.7)")
                elif r_squared > 0.5:
                    st.info("à¹à¸šà¸šà¸ˆà¸³à¸¥à¸­à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸›à¸²à¸™à¸à¸¥à¸²à¸‡ (RÂ² > 0.5)")
                else:
                    st.warning("à¹à¸šà¸šà¸ˆà¸³à¸¥à¸­à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸•à¹ˆà¸³ (RÂ² < 0.5) à¸­à¸²à¸ˆà¸•à¹‰à¸­à¸‡à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡")
                
                # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™
                error_fig = px.histogram(
                    pred_df,
                    x='error',
                    nbins=30,
                    title="à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹ƒà¸™à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢",
                    labels={'error': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)'}
                )
                
                error_fig.add_vline(x=0, line_width=2, line_dash="dash", line_color="red")
                st.plotly_chart(error_fig, use_container_width=True)
                
                # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡
                error_scatter = px.scatter(
                    pred_df,
                    x='time_taken',
                    y='error',
                    title="à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ˆà¸£à¸´à¸‡",
                    labels={
                        'time_taken': 'à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ˆà¸£à¸´à¸‡ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)',
                        'error': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)'
                    }
                )
                
                error_scatter.add_hline(y=0, line_width=2, line_dash="dash", line_color="red")
                st.plotly_chart(error_scatter, use_container_width=True)
                
                # à¹à¸ªà¸”à¸‡à¸à¸£à¸“à¸µà¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¢à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸” (à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”)
                st.subheader("à¸à¸£à¸“à¸µà¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¢à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸” (à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”)")
                worst_predictions = pred_df.sort_values('abs_error', ascending=False).head(10)
                st.dataframe(worst_predictions[['comment', 'time_taken', 'predicted_time', 'error', 'abs_error']])
            
            with pred_tab3:
                st.subheader("à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸•à¸²à¸¡à¹€à¸‚à¸•")
                
                # à¸”à¸¶à¸‡à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¹€à¸‚à¸•
                district_cols = [col for col in pred_df.columns if col.startswith('organization_')]
                
                if district_cols:
                    # à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹€à¸‚à¸•à¸«à¸¥à¸±à¸ (à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸°à¹à¸–à¸§)
                    pred_df['main_district'] = pred_df[district_cols].idxmax(axis=1)
                    
                    # à¹à¸›à¸¥à¸‡à¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                    pred_df['main_district'] = pred_df['main_district'].str.replace('organization_', '')
                    
                    # à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¹€à¸‚à¸•
                    district_accuracy = pred_df.groupby('main_district').agg({
                        'time_taken': 'mean',
                        'predicted_time': 'mean',
                        'abs_error': 'mean',
                        'pct_error': lambda x: np.abs(x).mean()
                    }).reset_index()
                    
                    district_accuracy = district_accuracy.rename(columns={
                        'time_taken': 'à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        'predicted_time': 'à¹€à¸§à¸¥à¸²à¸—à¸³à¸™à¸²à¸¢à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        'abs_error': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        'pct_error': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™ %'
                    })
                    
                    # à¹€à¸£à¸µà¸¢à¸‡à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢
                    district_accuracy = district_accuracy.sort_values('à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢')
                    
                    # à¹à¸ªà¸”à¸‡à¸•à¸²à¸£à¸²à¸‡
                    st.dataframe(district_accuracy)
                    
                    # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸•à¸²à¸¡à¹€à¸‚à¸•
                    accuracy_fig = px.bar(
                        district_accuracy,
                        x='main_district',
                        y='à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        title="à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¹€à¸‚à¸•",
                        color='à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                        labels={
                            'main_district': 'à¹€à¸‚à¸•',
                            'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)'
                        }
                    )
                    
                    accuracy_fig.update_layout(xaxis_tickangle=-45)
                    st.plotly_chart(accuracy_fig, use_container_width=True)
                    
                    # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¸à¸±à¸šà¸—à¸³à¸™à¸²à¸¢à¸•à¸²à¸¡à¹€à¸‚à¸•
                    compare_fig = px.bar(
                        district_accuracy,
                        x='main_district',
                        y=['à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢', 'à¹€à¸§à¸¥à¸²à¸—à¸³à¸™à¸²à¸¢à¹€à¸‰à¸¥à¸µà¹ˆà¸¢'],
                        barmode='group',
                        title="à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹à¸¥à¸°à¹€à¸§à¸¥à¸²à¸—à¸³à¸™à¸²à¸¢à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¹€à¸‚à¸•",
                        labels={'main_district': 'à¹€à¸‚à¸•', 'value': 'à¹€à¸§à¸¥à¸² (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)', 'variable': ''}
                    )
                    
                    compare_fig.update_layout(xaxis_tickangle=-45)
                    st.plotly_chart(compare_fig, use_container_width=True)
                    
                    # à¹à¸ªà¸”à¸‡à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹à¸¥à¸°à¹à¸¢à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸”
                    st.subheader("à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹à¸¥à¸°à¹à¸¢à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸”")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        best_districts = district_accuracy.head(5)
                        st.write("à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”:")
                        st.dataframe(best_districts[['main_district', 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢']])
                    
                    with col2:
                        worst_districts = district_accuracy.sort_values('à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢', ascending=False).head(5)
                        st.write("à¹€à¸‚à¸•à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”:")
                        st.dataframe(worst_districts[['main_district', 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢']])
                else:
                    st.warning("à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‚à¸•à¹ƒà¸™à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
            
            with pred_tab4:
                st.subheader("à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²")
                
                # à¸”à¸¶à¸‡à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸² (à¹„à¸¡à¹ˆà¸£à¸§à¸¡ organization_ à¹à¸¥à¸° à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸­à¸·à¹ˆà¸™à¹† à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡)
                issue_cols = [col for col in pred_df.columns if col not in [
                    'Unnamed: 0', 'comment', 'time_taken', 'predicted_time', 'error', 'abs_error', 
                    'squared_error', 'pct_error', 'main_district'
                ] and not col.startswith('organization_')]
                
                if issue_cols:
                    # à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸«à¸¥à¸±à¸ (à¸›à¸£à¸°à¹€à¸ à¸—à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸°à¹à¸–à¸§)
                    if len(issue_cols) > 0:
                        pred_df['main_issue'] = pred_df[issue_cols].idxmax(axis=1)
                        
                        # à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²
                        issue_accuracy = pred_df.groupby('main_issue').agg({
                            'time_taken': 'mean',
                            'predicted_time': 'mean',
                            'abs_error': 'mean',
                            'pct_error': lambda x: np.abs(x).mean()
                        }).reset_index()
                        
                        issue_accuracy = issue_accuracy.rename(columns={
                            'time_taken': 'à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                            'predicted_time': 'à¹€à¸§à¸¥à¸²à¸—à¸³à¸™à¸²à¸¢à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                            'abs_error': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                            'pct_error': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™ %'
                        })
                        
                        # à¹€à¸£à¸µà¸¢à¸‡à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢
                        issue_accuracy = issue_accuracy.sort_values('à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢')
                        
                        # à¹à¸ªà¸”à¸‡à¸•à¸²à¸£à¸²à¸‡
                        st.dataframe(issue_accuracy)
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²
                        issue_fig = px.bar(
                            issue_accuracy,
                            x='main_issue',
                            y='à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                            title="à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²",
                            color='à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢',
                            labels={
                                'main_issue': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²',
                                'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)'
                            }
                        )
                        
                        issue_fig.update_layout(xaxis_tickangle=-45)
                        st.plotly_chart(issue_fig, use_container_width=True)
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¸à¸±à¸šà¸—à¸³à¸™à¸²à¸¢à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²
                        issue_compare_fig = px.bar(
                            issue_accuracy,
                            x='main_issue',
                            y=['à¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢', 'à¹€à¸§à¸¥à¸²à¸—à¸³à¸™à¸²à¸¢à¹€à¸‰à¸¥à¸µà¹ˆà¸¢'],
                            barmode='group',
                            title="à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸ˆà¸£à¸´à¸‡à¹à¸¥à¸°à¹€à¸§à¸¥à¸²à¸—à¸³à¸™à¸²à¸¢à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²",
                            labels={'main_issue': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²', 'value': 'à¹€à¸§à¸¥à¸² (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)', 'variable': ''}
                        )
                        
                        issue_compare_fig.update_layout(xaxis_tickangle=-45)
                        st.plotly_chart(issue_compare_fig, use_container_width=True)
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¸‚à¸­à¸‡à¸›à¸±à¸à¸«à¸²à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
                        # (à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸²à¸ˆà¸³à¸™à¸§à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸„à¸·à¸­à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™)
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸ˆà¸³à¸™à¸§à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡
                        pred_df['issue_count'] = pred_df[issue_cols].sum(axis=1)
                        
                        # à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸•à¸²à¸¡à¸ˆà¸³à¸™à¸§à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²
                        complexity_accuracy = pred_df.groupby('issue_count').agg({
                            'time_taken': 'mean',
                            'predicted_time': 'mean',
                            'abs_error': 'mean'
                        }).reset_index()
                        
                        # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿ
                        complexity_fig = px.line(
                            complexity_accuracy,
                            x='issue_count',
                            y='abs_error',
                            markers=True,
                            title="à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¸‚à¸­à¸‡à¸›à¸±à¸à¸«à¸²",
                            labels={
                                'issue_count': 'à¸ˆà¸³à¸™à¸§à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡',
                                'abs_error': 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)'
                            }
                        )
                        
                        st.plotly_chart(complexity_fig, use_container_width=True)
                        
                        # à¹à¸ªà¸”à¸‡à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹à¸¥à¸°à¹à¸¢à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸”
                        st.subheader("à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹à¸¥à¸°à¹à¸¢à¹ˆà¸—à¸µà¹ˆà¸ªà¸¸à¸”")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            best_issues = issue_accuracy.head(5)
                            st.write("à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”:")
                            st.dataframe(best_issues[['main_issue', 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢']])
                        
                        with col2:
                            worst_issues = issue_accuracy.sort_values('à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢', ascending=False).head(5)
                            st.write("à¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸™à¹‰à¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”:")
                            st.dataframe(worst_issues[['main_issue', 'à¸„à¸§à¸²à¸¡à¸„à¸¥à¸²à¸”à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢']])
                    else:
                        st.warning("à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸›à¸£à¸°à¹€à¸ à¸—à¸›à¸±à¸à¸«à¸²")
        except Exception as e:
            st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¸«à¸£à¸·à¸­à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {e}")
    else:
        st.warning(f"à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œ {pred_file} à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ à¹‚à¸›à¸£à¸”à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
        
        # à¹€à¸ªà¸™à¸­à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸à¹ƒà¸™à¸à¸²à¸£à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ
        uploaded_file = st.file_uploader("à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ CSV à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ time_taken à¹à¸¥à¸° predicted_time", type=["csv"])
        
        if uploaded_file is not None:
            try:
                pred_df = pd.read_csv(uploaded_file)
                
                # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
                required_cols = ['time_taken', 'predicted_time']
                
                if all(col in pred_df.columns for col in required_cols):
                    st.success("à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")
                    
                    # à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¹‚à¸„à¹‰à¸”à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸šà¸”à¹‰à¸²à¸™à¸šà¸™à¸—à¸µà¹ˆà¸™à¸µà¹ˆ
                    # ... (à¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸±à¸”à¸¥à¸­à¸à¹‚à¸„à¹‰à¸”à¸ˆà¸²à¸à¸”à¹‰à¸²à¸™à¸šà¸™à¸¡à¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰)
                else:
                    st.error(f"à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ: {', '.join(required_cols)}")
            except Exception as e:
                st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ: {e}")


# Footer
st.markdown("""
---
### About This Dashboard
This dashboard was created using Streamlit, Plotly, and other data analysis libraries to visualize and analyze data from Traffy Fondue.
The analysis focuses on understanding the types of issues reported, response times, textual patterns in user comments, and the relationship with rainfall data.
""")